{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CJPK45sduVul"
   },
   "source": [
    "**Stage 1 - Data Generation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 34023,
     "status": "ok",
     "timestamp": 1767071194140,
     "user": {
      "displayName": "Stefan Lafon",
      "userId": "17149650627927548318"
     },
     "user_tz": 480
    },
    "id": "xAV9t0Xhf7ye",
    "outputId": "d7a46841-65c6-4935-8072-c0ab01888417"
   },
   "outputs": [],
   "source": [
    "# @title 1. Setup and dependencies\n",
    "import sys\n",
    "import os\n",
    "import subprocess\n",
    "import importlib.util\n",
    "\n",
    "# Install necessary system and python libraries for rendering.\n",
    "print(\"Installing dependencies...\")\n",
    "try:\n",
    "    import moderngl\n",
    "except ImportError:\n",
    "    subprocess.check_call(['apt-get', 'install', '-y', 'libgl1-mesa-glx'])\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"moderngl\"])\n",
    "    import moderngl\n",
    "\n",
    "import random\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Mount drive to access the project directory using the specific path provided.\n",
    "from google.colab import drive\n",
    "if not os.path.exists('/content/drive'):\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "# Correct path containing the space in My Drive.\n",
    "PROJECT_ROOT = '/content/drive/My Drive/projects/EarthShader'\n",
    "sys.path.append(PROJECT_ROOT)\n",
    "LIB_DIR = os.path.join(PROJECT_ROOT, 'lib')\n",
    "\n",
    "# Ensure the library directory is in the path for custom imports.\n",
    "if LIB_DIR not in sys.path:\n",
    "    sys.path.insert(0, LIB_DIR)\n",
    "\n",
    "# Configuration for the Stage 1 dataset.\n",
    "DATASET_ROOT = os.path.join(PROJECT_ROOT, 'dataset/stage1')\n",
    "IMAGES_DIR = os.path.join(DATASET_ROOT, 'images')\n",
    "JSONL_PATH = os.path.join(DATASET_ROOT, 'dataset.jsonl')\n",
    "NUM_SAMPLES = 5000\n",
    "IMG_SIZE = 512\n",
    "\n",
    "os.makedirs(IMAGES_DIR, exist_ok=True)\n",
    "print(f\"Setup complete. Dataset will be saved to: {DATASET_ROOT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1930,
     "status": "ok",
     "timestamp": 1767071196074,
     "user": {
      "displayName": "Stefan Lafon",
      "userId": "17149650627927548318"
     },
     "user_tz": 480
    },
    "id": "GpuQPXD-aSXN",
    "outputId": "b69a3cf2-1c40-4f06-ae69-9570b59cac95"
   },
   "outputs": [],
   "source": [
    "# @title 2. Import generator logic\n",
    "try:\n",
    "    # Attempt standard package import first.\n",
    "    from lib.generators.primitives import generate_primitive\n",
    "    from lib.gl_renderer import ShaderRenderer\n",
    "    print(\"Library loaded successfully via standard import.\")\n",
    "except ImportError as e:\n",
    "    print(f\"Standard import failed ({e}). Trying direct file load...\")\n",
    "\n",
    "    # Direct loading if Colab pathing is inconsistent.\n",
    "    import importlib.util\n",
    "\n",
    "    # Use the PROJECT_ROOT defined in Cell 1.\n",
    "    LIB_DIR = os.path.join(PROJECT_ROOT, 'lib')\n",
    "\n",
    "    # Load the renderer module.\n",
    "    spec_r = importlib.util.spec_from_file_location(\"gl_renderer\", os.path.join(LIB_DIR, \"gl_renderer.py\"))\n",
    "    mod_r = importlib.util.module_from_spec(spec_r)\n",
    "    spec_r.loader.exec_module(mod_r)\n",
    "    ShaderRenderer = mod_r.ShaderRenderer\n",
    "\n",
    "    # Load the base generator module.\n",
    "    spec_b = importlib.util.spec_from_file_location(\"base\", os.path.join(LIB_DIR, \"generators/base.py\"))\n",
    "    mod_b = importlib.util.module_from_spec(spec_b)\n",
    "    spec_b.loader.exec_module(mod_b)\n",
    "\n",
    "    # Load the primitives generator module and manually inject the base dependency.\n",
    "    spec_p = importlib.util.spec_from_file_location(\"primitives\", os.path.join(LIB_DIR, \"generators/primitives.py\"))\n",
    "    mod_p = importlib.util.module_from_spec(spec_p)\n",
    "    mod_p.base = mod_b\n",
    "    spec_p.loader.exec_module(mod_p)\n",
    "\n",
    "    generate_primitive = mod_p.generate_primitive\n",
    "    print(\"Direct file load successful.\")\n",
    "\n",
    "# Verify that the generator is working correctly before starting the bulk run.\n",
    "print(\"\\n--- Testing Generator ---\")\n",
    "test_code, test_analysis = generate_primitive(0)\n",
    "print(f\"Generator test passed. Sample analysis:\\n{test_analysis[:200]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 230909,
     "status": "ok",
     "timestamp": 1767071426985,
     "user": {
      "displayName": "Stefan Lafon",
      "userId": "17149650627927548318"
     },
     "user_tz": 480
    },
    "id": "u7iphw6raWWs",
    "outputId": "f37d91e9-b424-4062-f5c5-8dd7b2b01561"
   },
   "outputs": [],
   "source": [
    "# @title 3. Generation loop and storage\n",
    "# Set to True to wipe existing data and start over, or False to resume.\n",
    "FORCE_REGEN = True\n",
    "\n",
    "if 'renderer' not in locals():\n",
    "    renderer = ShaderRenderer(width=IMG_SIZE, height=IMG_SIZE)\n",
    "    print(\"Renderer initialized.\")\n",
    "\n",
    "dataset_entries = []\n",
    "failed_count = 0\n",
    "\n",
    "# Track statistics for dataset distribution.\n",
    "stats = {\n",
    "    'single_circle': 0,\n",
    "    'single_square': 0,\n",
    "    'single_ring': 0,\n",
    "    'composition': 0\n",
    "}\n",
    "\n",
    "if FORCE_REGEN:\n",
    "    print(\"[FORCE REGEN] Wiping existing registry...\")\n",
    "    with open(JSONL_PATH, 'w') as f:\n",
    "        pass\n",
    "    existing_count = 0\n",
    "else:\n",
    "    if os.path.exists(JSONL_PATH):\n",
    "        with open(JSONL_PATH, 'r') as f:\n",
    "            existing_count = sum(1 for line in f)\n",
    "        print(f\"Found {existing_count} existing samples.\")\n",
    "    else:\n",
    "        with open(JSONL_PATH, 'w') as f:\n",
    "            pass\n",
    "        existing_count = 0\n",
    "\n",
    "if existing_count < NUM_SAMPLES:\n",
    "    print(f\"Generating samples {existing_count} to {NUM_SAMPLES}...\")\n",
    "    pbar = tqdm(range(existing_count, NUM_SAMPLES), desc=\"Generating\")\n",
    "\n",
    "    for i in pbar:\n",
    "        try:\n",
    "            # Call the SDF-focused generator.\n",
    "            code, analysis = generate_primitive(i)\n",
    "\n",
    "            filename = f\"stage1_{i:05d}.png\"\n",
    "            filepath = os.path.join(IMAGES_DIR, filename)\n",
    "\n",
    "            # Render the GLSL code to a file.\n",
    "            success = renderer.render(code, filepath)\n",
    "\n",
    "            if success:\n",
    "                # Update distribution statistics.\n",
    "                if 'Composition' in analysis:\n",
    "                    stats['composition'] += 1\n",
    "                elif 'Circle' in analysis:\n",
    "                    stats['single_circle'] += 1\n",
    "                elif 'Square' in analysis:\n",
    "                    stats['single_square'] += 1\n",
    "                elif 'Ring' in analysis:\n",
    "                    stats['single_ring'] += 1\n",
    "\n",
    "                entry = {\n",
    "                    \"image_path\": filepath,\n",
    "                    \"analysis\": analysis,\n",
    "                    \"code\": code\n",
    "                }\n",
    "                dataset_entries.append(entry)\n",
    "\n",
    "                # Incremental Save to prevent data loss.\n",
    "                if len(dataset_entries) >= 100:\n",
    "                    with open(JSONL_PATH, 'a') as f:\n",
    "                        for e in dataset_entries:\n",
    "                            f.write(json.dumps(e) + '\\n')\n",
    "                    dataset_entries = []\n",
    "\n",
    "                    pbar.set_postfix({\n",
    "                        'fails': failed_count,\n",
    "                        'comp': stats['composition']\n",
    "                    })\n",
    "            else:\n",
    "                failed_count += 1\n",
    "                pbar.set_description(f\"Gen ({failed_count} fails)\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"\\n[CRITICAL ERROR] Sample {i}: {e}\")\n",
    "            failed_count += 1\n",
    "\n",
    "    # Final flush for any remaining entries.\n",
    "    if dataset_entries:\n",
    "        with open(JSONL_PATH, 'a') as f:\n",
    "            for e in dataset_entries:\n",
    "                f.write(json.dumps(e) + '\\n')\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"GENERATION COMPLETE\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Total Samples Saved: {NUM_SAMPLES - failed_count}\")\n",
    "    print(f\"Final Distribution: {stats}\")\n",
    "else:\n",
    "    print(\"Dataset already complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 217,
     "status": "ok",
     "timestamp": 1767071427205,
     "user": {
      "displayName": "Stefan Lafon",
      "userId": "17149650627927548318"
     },
     "user_tz": 480
    },
    "id": "fwbRcstdW8ak",
    "outputId": "4779ed04-5e9e-4bec-97ad-ffac6474b771"
   },
   "outputs": [],
   "source": [
    "# @title 4. Validator and strict canonical check\n",
    "import re\n",
    "import json\n",
    "import os\n",
    "\n",
    "def validate_canonical_data():\n",
    "    \"\"\"\n",
    "    Analyzes the dataset to ensure high logic diversity and low code variance.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(JSONL_PATH):\n",
    "        print(\"Dataset not found. Please run the generation loop first.\")\n",
    "        return\n",
    "\n",
    "    print(\"Analyzing dataset structure for SDF reasoning diversity...\\n\")\n",
    "    with open(JSONL_PATH, 'r') as f:\n",
    "        entries = [json.loads(line) for line in f]\n",
    "\n",
    "    total = len(entries)\n",
    "    unique_code_logic = set()\n",
    "    unique_analyses = set()\n",
    "\n",
    "    for entry in entries:\n",
    "        full_code = entry['code']\n",
    "\n",
    "        # 1. Extract pure GLSL logic by removing the analysis comments.\n",
    "        glsl_logic = re.sub(r'/\\*.*?\\*/', '', full_code, flags=re.DOTALL)\n",
    "\n",
    "        # 2. Normalize logic to check for structural consistency.\n",
    "        # We strip numbers and whitespace to see if the underlying formula patterns match.\n",
    "        normalized_logic = ''.join(c for c in glsl_logic if c.isalpha())\n",
    "        unique_code_logic.add(normalized_logic)\n",
    "\n",
    "        # 3. Extract the Analysis block to verify variety in reasoning.\n",
    "        analysis_match = re.search(r'/\\* ANALYSIS\\n(.*?)\\n\\*/', full_code, flags=re.DOTALL)\n",
    "        if analysis_match:\n",
    "            unique_analyses.add(analysis_match.group(1).strip())\n",
    "\n",
    "    print(f\"Metrics for {total} samples:\")\n",
    "    print(f\"   Unique Logic Structures: {len(unique_code_logic)}\")\n",
    "    print(f\"   Unique Analysis Blocks:  {len(unique_analyses)}\")\n",
    "\n",
    "    # Validation Report\n",
    "    print(\"\\nReport:\")\n",
    "\n",
    "    # We expect some variance due to variable randomization, but the structure should be stable.\n",
    "    if len(unique_code_logic) < 100:\n",
    "        print(\"   [PASS] Code structure is consistent and follows SDF patterns.\")\n",
    "    else:\n",
    "        print(f\"   [WARNING] High logic variance ({len(unique_code_logic)}). Check variable randomization.\")\n",
    "\n",
    "    # High analysis variance is the primary goal for teaching reasoning.\n",
    "    if len(unique_analyses) > (total * 0.05):\n",
    "        print(\"   [PASS] Analysis reasoning is sufficiently diverse.\")\n",
    "    else:\n",
    "        print(\"   [FAIL] Analysis is repetitive. Risk of model overfitting.\")\n",
    "\n",
    "validate_canonical_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 749
    },
    "executionInfo": {
     "elapsed": 85,
     "status": "ok",
     "timestamp": 1767071427300,
     "user": {
      "displayName": "Stefan Lafon",
      "userId": "17149650627927548318"
     },
     "user_tz": 480
    },
    "id": "v8TqUQAagX6o",
    "outputId": "0baaddc6-50d1-44fc-f302-97c6907389c8"
   },
   "outputs": [],
   "source": [
    "# @title 5. Inspector and visual audit\n",
    "import random\n",
    "from IPython.display import display, HTML\n",
    "import base64\n",
    "import json\n",
    "import os\n",
    "\n",
    "def inspect_random_sample():\n",
    "    \"\"\"\n",
    "    Picks a random sample from the dataset and displays the code and image.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(JSONL_PATH):\n",
    "        print(f\"Dataset registry not found at {JSONL_PATH}.\")\n",
    "        return\n",
    "\n",
    "    # Load all entries to select a random candidate.\n",
    "    with open(JSONL_PATH, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    if not lines:\n",
    "        print(\"Dataset registry is empty.\")\n",
    "        return\n",
    "\n",
    "    # Select and parse a random entry.\n",
    "    line = random.choice(lines)\n",
    "    entry = json.loads(line)\n",
    "\n",
    "    img_path = entry['image_path']\n",
    "    code = entry['code']\n",
    "    analysis = entry['analysis']\n",
    "\n",
    "    if os.path.exists(img_path):\n",
    "        # Encode the image to base64 for inline HTML display.\n",
    "        with open(img_path, 'rb') as f:\n",
    "            img_data = base64.b64encode(f.read()).decode()\n",
    "\n",
    "        # Escape special characters in the GLSL code for HTML safety.\n",
    "        code_html = code.replace('&', '&amp;').replace('<', '&lt;').replace('>', '&gt;')\n",
    "\n",
    "        # Build a clean side-by-side layout.\n",
    "        html = f\"\"\"\n",
    "        <div style=\"display: flex; gap: 20px; font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\">\n",
    "            <div style=\"flex: 1; background: #fafafa; padding: 15px; border: 1px solid #eee; border-radius: 8px; overflow-x: auto;\">\n",
    "                <h3 style=\"margin-top: 0; color: #333;\">Generated GLSL Logic</h3>\n",
    "                <pre style=\"white-space: pre-wrap; font-size: 12px; color: #444;\">{code_html}</pre>\n",
    "            </div>\n",
    "            <div style=\"flex: 1; text-align: center;\">\n",
    "                <h3 style=\"margin-top: 0; color: #333;\">Rendered Output</h3>\n",
    "                <img src=\"data:image/png;base64,{img_data}\" style=\"max-width: 100%; border-radius: 4px; border: 1px solid #ddd; box-shadow: 0 2px 5px rgba(0,0,0,0.1);\">\n",
    "            </div>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "\n",
    "        display(HTML(html))\n",
    "\n",
    "        # Print the analysis reasoning block clearly below the visual.\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"SDF REASONING ANALYSIS:\")\n",
    "        print(\"=\"*70)\n",
    "        print(analysis)\n",
    "        print(\"=\"*70)\n",
    "    else:\n",
    "        print(f\"Image file missing at path: {img_path}\")\n",
    "\n",
    "# Run the inspector.\n",
    "inspect_random_sample()\n",
    "\n",
    "# Suggestion for the user to verify diversity.\n",
    "print(\"\\nTip: Run this cell multiple times to see different SDF variable names and reasoning patterns.\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNSJ+J8JNqdiTAkZpVmnvT9",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
