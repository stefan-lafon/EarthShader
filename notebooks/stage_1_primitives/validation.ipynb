{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "htfgqge_kAIY"
   },
   "source": [
    "**Stage 1 - Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "lgGsUkWyiUjO"
   },
   "outputs": [],
   "source": [
    "# @title 1. Install Dependencies\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# 1.1 Force Upgrade Libraries\n",
    "print(\"Installing libraries...\")\n",
    "!pip install -q -U bitsandbytes\n",
    "!pip install -q -U git+https://github.com/huggingface/transformers peft accelerate\n",
    "!pip install -q moderngl\n",
    "!apt-get install -y libgl1-mesa-glx > /dev/null\n",
    "\n",
    "# 1.2 Restart Check\n",
    "try:\n",
    "    import bitsandbytes\n",
    "    from transformers.utils import is_bitsandbytes_available\n",
    "    if not is_bitsandbytes_available():\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"  PLEASE RESTART RUNTIME (Runtime > Restart Session)\")\n",
    "        print(\"Then run this cell again.\")\n",
    "        print(\"=\"*60 + \"\\n\")\n",
    "    else:\n",
    "        print(\"  Environment Ready.\")\n",
    "except ImportError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "VffXDzuemewD"
   },
   "outputs": [],
   "source": [
    "# @title 2. Load Model, Adapter & STRICT Renderer\n",
    "import torch\n",
    "from transformers import Qwen2VLForConditionalGeneration, Qwen2VLProcessor, BitsAndBytesConfig\n",
    "from peft import PeftModel\n",
    "import os\n",
    "import sys\n",
    "import moderngl\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# 1. Configuration\n",
    "PROJECT_ROOT = '/content/drive/MyDrive/projects/EarthShader'\n",
    "ADAPTER_PATH = os.path.join(PROJECT_ROOT, 'checkpoints/stage1_final')\n",
    "LIB_DIR = os.path.join(PROJECT_ROOT, 'lib')\n",
    "\n",
    "# 2. Mount Drive\n",
    "from google.colab import drive\n",
    "if not os.path.exists('/content/drive'):\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "# 3. --- STRICT RENDERER ---\n",
    "class ShaderRenderer:\n",
    "    def __init__(self, width=256, height=256):\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.ctx = None\n",
    "\n",
    "        # ATTEMPT 1: EGL (Required for Colab)\n",
    "        try:\n",
    "            self.ctx = moderngl.create_context(standalone=True, backend='egl')\n",
    "            print(\"[Renderer] Success: EGL Backend initialized.\")\n",
    "        except Exception as e:\n",
    "            print(f\"[Renderer] EGL Failed: {e}\")\n",
    "            # ATTEMPT 2: Standard (Fallback - usually fails on Colab)\n",
    "            try:\n",
    "                self.ctx = moderngl.create_context(standalone=True)\n",
    "                print(\"[Renderer] Warning: Using Standard Backend (May produce noise).\")\n",
    "            except Exception as e2:\n",
    "                raise Exception(f\"CRITICAL: Could not create ANY ModernGL context.\\nEGL: {e}\\nStd: {e2}\")\n",
    "\n",
    "        # Geometry\n",
    "        vertices = np.array([-1.0, -1.0, 1.0, -1.0, -1.0, 1.0, 1.0, 1.0], dtype='f4')\n",
    "        self.vbo = self.ctx.buffer(vertices.tobytes())\n",
    "        self.fbo = self.ctx.simple_framebuffer((self.width, self.height), components=3)\n",
    "        self.vert_shader = '''\n",
    "        #version 330\n",
    "        in vec2 in_vert;\n",
    "        out vec2 uv;\n",
    "        void main() {\n",
    "            uv = in_vert;\n",
    "            gl_Position = vec4(in_vert, 0.0, 1.0);\n",
    "        }\n",
    "        '''\n",
    "\n",
    "        # Load Common Lib\n",
    "        common_path = os.path.join(LIB_DIR, 'common.glsl')\n",
    "        self.common_lib = \"\"\n",
    "        if os.path.exists(common_path):\n",
    "            with open(common_path, 'r') as f:\n",
    "                self.common_lib = f.read()\n",
    "            print(f\"[Renderer] common.glsl loaded ({len(self.common_lib)} chars).\")\n",
    "        else:\n",
    "            print(f\"[Renderer] WARNING: common.glsl NOT FOUND at {common_path}\")\n",
    "\n",
    "    def render(self, fragment_code, output_path):\n",
    "        full_frag_shader = f'''\n",
    "        #version 330\n",
    "        uniform vec2 iResolution;\n",
    "        out vec4 fragColor;\n",
    "        {self.common_lib}\n",
    "        {fragment_code}\n",
    "        void main() {{\n",
    "            vec4 color;\n",
    "            mainImage(color, gl_FragCoord.xy);\n",
    "            fragColor = color;\n",
    "        }}\n",
    "        '''\n",
    "        try:\n",
    "            prog = self.ctx.program(vertex_shader=self.vert_shader, fragment_shader=full_frag_shader)\n",
    "            if 'iResolution' in prog: prog['iResolution'].value = (self.width, self.height)\n",
    "            vao = self.ctx.simple_vertex_array(prog, self.vbo, 'in_vert')\n",
    "\n",
    "            # CLEAR AND RENDER\n",
    "            self.fbo.use()\n",
    "            self.fbo.clear(0.0, 0.0, 0.0, 1.0) # Clear to Black\n",
    "            vao.render(moderngl.TRIANGLE_STRIP)\n",
    "\n",
    "            # READ\n",
    "            data = self.fbo.read(components=3)\n",
    "            image = Image.frombytes('RGB', self.fbo.size, data).transpose(Image.FLIP_TOP_BOTTOM)\n",
    "            image.save(output_path)\n",
    "\n",
    "            # Cleanup\n",
    "            vao.release()\n",
    "            prog.release()\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            # print(f\"Render Error: {e}\") # Uncomment to debug shader errors\n",
    "            return False\n",
    "\n",
    "# Initialize\n",
    "renderer = ShaderRenderer(width=256, height=256)\n",
    "\n",
    "# 4. Load Model\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    ")\n",
    "base_model = Qwen2VLForConditionalGeneration.from_pretrained(\n",
    "    \"Qwen/Qwen2-VL-7B-Instruct\",\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16,\n",
    ")\n",
    "model = PeftModel.from_pretrained(base_model, ADAPTER_PATH)\n",
    "model.eval()\n",
    "processor = Qwen2VLProcessor.from_pretrained(ADAPTER_PATH, min_pixels=256*256, max_pixels=256*256)\n",
    "print(\"[SUCCESS] Pipeline Ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x_dkDGv2p1wp"
   },
   "outputs": [],
   "source": [
    "# @title 3. Inference: The Full Diagnostic (5-Column View)\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torch\n",
    "import os\n",
    "import sys\n",
    "import importlib.util\n",
    "import textwrap\n",
    "\n",
    "# 1. Import Generator Logic\n",
    "try:\n",
    "    from generators.primitives import generate_primitive\n",
    "except ImportError:\n",
    "    spec_b = importlib.util.spec_from_file_location(\"base\", os.path.join(LIB_DIR, \"generators/base.py\"))\n",
    "    mod_b = importlib.util.module_from_spec(spec_b)\n",
    "    spec_b.loader.exec_module(mod_b)\n",
    "    spec_p = importlib.util.spec_from_file_location(\"primitives\", os.path.join(LIB_DIR, \"generators/primitives.py\"))\n",
    "    mod_p = importlib.util.module_from_spec(spec_p)\n",
    "    mod_p.base = mod_b\n",
    "    spec_p.loader.exec_module(mod_p)\n",
    "    generate_primitive = mod_p.generate_primitive\n",
    "\n",
    "# 2. Helpers\n",
    "def parse_response(text):\n",
    "    \"\"\"Splits model output into Analysis and Code sections.\"\"\"\n",
    "    # Find code start\n",
    "    code_start_markers = [\"```glsl\", \"void mainImage\"]\n",
    "    idx = -1\n",
    "    for marker in code_start_markers:\n",
    "        idx = text.find(marker)\n",
    "        if idx != -1:\n",
    "            break\n",
    "\n",
    "    if idx != -1:\n",
    "        analysis = text[:idx].strip()\n",
    "        code_raw = text[idx:].strip()\n",
    "        # Clean Markdown\n",
    "        if code_raw.startswith(\"```glsl\"):\n",
    "            code_raw = code_raw[7:]\n",
    "        if code_raw.endswith(\"```\"):\n",
    "            code_raw = code_raw[:-3]\n",
    "        return analysis, code_raw.strip()\n",
    "    else:\n",
    "        return text, \"\" # No code found\n",
    "\n",
    "# 3. Inference Loop\n",
    "print(\"Running Inference on 3 Random Samples (Full Diagnostic)...\\n\")\n",
    "# Extra wide layout for 5 columns\n",
    "plt.figure(figsize=(30, 12))\n",
    "\n",
    "rows = 3\n",
    "cols = 5\n",
    "\n",
    "for i in range(rows):\n",
    "    print(f\"Sample {i+1}/{rows}...\")\n",
    "\n",
    "    # A. Generate Ground Truth (Input)\n",
    "    gt_code, gt_analysis = generate_primitive(random.randint(0, 100000))\n",
    "    renderer.render(gt_code, \"temp_gt.png\")\n",
    "    gt_image = Image.open(\"temp_gt.png\").convert(\"RGB\")\n",
    "\n",
    "    # B. Prompt\n",
    "    conversation = [\n",
    "        {\"role\": \"user\", \"content\": [\n",
    "            {\"type\": \"image\"},\n",
    "            {\"type\": \"text\", \"text\": \"Reverse engineer the GLSL shader code for this texture. Include analysis.\"}\n",
    "        ]}\n",
    "    ]\n",
    "    text_prompt = processor.apply_chat_template(conversation, add_generation_prompt=True, tokenize=False)\n",
    "    inputs = processor(text=[text_prompt], images=[gt_image], padding=True, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    # C. Generate\n",
    "    with torch.no_grad():\n",
    "        output_ids = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=1024,\n",
    "            do_sample=False,\n",
    "        )\n",
    "\n",
    "    # D. Process Output\n",
    "    generated_ids = output_ids[:, inputs.input_ids.shape[1]:]\n",
    "    output_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "\n",
    "    # Split Analysis vs Code\n",
    "    pred_analysis, pred_code = parse_response(output_text)\n",
    "\n",
    "    # Render Prediction\n",
    "    pred_success = renderer.render(pred_code, f\"temp_pred_{i}.png\")\n",
    "    pred_image = Image.open(f\"temp_pred_{i}.png\") if pred_success else Image.new(\"RGB\", (256, 256), (255, 0, 0))\n",
    "\n",
    "    # --- VISUALIZATION ---\n",
    "\n",
    "    # Col 1: Input (GT)\n",
    "    plt.subplot(rows, cols, i*cols + 1)\n",
    "    plt.imshow(gt_image)\n",
    "    plt.title(\"Input (GT)\", fontweight='bold')\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Col 2: Prediction\n",
    "    plt.subplot(rows, cols, i*cols + 2)\n",
    "    plt.imshow(pred_image)\n",
    "    plt.title(\"Prediction\", fontweight='bold')\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Col 3: GT Analysis\n",
    "    ax = plt.subplot(rows, cols, i*cols + 3)\n",
    "    plt.text(0, 1, textwrap.fill(gt_analysis, width=35),\n",
    "             family='sans-serif', fontsize=9, verticalalignment='top')\n",
    "    plt.title(\"Ground Truth Logic\", fontweight='bold', color='green')\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Col 4: Pred Analysis (The \"Thought Process\")\n",
    "    ax = plt.subplot(rows, cols, i*cols + 4)\n",
    "    # If empty, warn user\n",
    "    disp_analysis = pred_analysis if pred_analysis else \"[NO ANALYSIS GENERATED]\"\n",
    "    plt.text(0, 1, textwrap.fill(disp_analysis, width=35),\n",
    "             family='sans-serif', fontsize=9, verticalalignment='top')\n",
    "    plt.title(\"Model's Logic\", fontweight='bold', color='blue')\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Col 5: Generated Code\n",
    "    ax = plt.subplot(rows, cols, i*cols + 5)\n",
    "    display_code = pred_code[:600] + (\"\\n...\" if len(pred_code) > 600 else \"\")\n",
    "    plt.text(0, 1, display_code, family='monospace', fontsize=8, verticalalignment='top')\n",
    "    plt.title(\"Generated Code\", fontweight='bold')\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyO1a+YzRL7V1FqP1yPvU5fu",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
