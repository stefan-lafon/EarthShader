{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "htfgqge_kAIY"
   },
   "source": [
    "**Stage 1 - Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 29511,
     "status": "ok",
     "timestamp": 1767370149031,
     "user": {
      "displayName": "Stefan Lafon",
      "userId": "17149650627927548318"
     },
     "user_tz": 480
    },
    "id": "lgGsUkWyiUjO",
    "outputId": "cf86349a-856b-429b-c37f-c900aacaf6e6"
   },
   "outputs": [],
   "source": [
    "# @title 1. Environment and paths setup\n",
    "import os\n",
    "import sys\n",
    "from google.colab import drive\n",
    "\n",
    "# 1. Mount drive to access the trained adapters and renderer.\n",
    "if not os.path.exists('/content/drive'):\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "# 2. Project paths using the correct Drive prefix.\n",
    "PROJECT_ROOT = '/content/drive/My Drive/projects/EarthShader'\n",
    "# Points to the committed stage 1 adapter folder.\n",
    "ADAPTER_PATH = os.path.join(PROJECT_ROOT, 'checkpoints/stage1_final')\n",
    "LIB_DIR = os.path.join(PROJECT_ROOT, 'lib')\n",
    "\n",
    "# 3. Ensure dependencies are present for the T4 environment.\n",
    "try:\n",
    "    import moderngl\n",
    "except ImportError:\n",
    "    print(\"Installing missing dependencies...\")\n",
    "    # These libraries are required for the vision tower and LoRA inference.\n",
    "    !pip install -q moderngl moderngl-window peft bitsandbytes accelerate qwen-vl-utils\n",
    "\n",
    "# 4. Link library for the renderer and generator.\n",
    "if LIB_DIR not in sys.path:\n",
    "    sys.path.append(LIB_DIR)\n",
    "\n",
    "from gl_renderer import ShaderRenderer\n",
    "\n",
    "# Initialize the renderer at 256 for faster validation cycles.\n",
    "# This resolution matches the max_pixels used during training.\n",
    "renderer = ShaderRenderer(width=256, height=256)\n",
    "\n",
    "print(f\"[SUCCESS] Environment ready. Renderer initialized at 256x256.\")\n",
    "print(f\"Validation path set to: {ADAPTER_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 636,
     "referenced_widgets": [
      "cd81b885daa74a48ad5702c12c702bd1",
      "a52377b2d55241b5b6ea3285ab5f6649",
      "251a8c532f11421b912df7712dd129a4",
      "21e1c5ee1fb04b6e9bc9a6ad8daef634",
      "3c45098cfab94741ac52f256fbf39f01",
      "c898f5acd3d143dcbe16ede09ee451dc",
      "0ca8a0dee3e24743bb31a936de0e08f6",
      "836af76a616a457c8b1ce99c48839168",
      "df0ee3bc261e4a7788ffdf582703dd0e",
      "0844e0c2e7bd4e7d9f9873323a285c8c",
      "7d382336a0b9495a9adbd8498e7de582",
      "82950fa98873441c9c66717c9e70396e",
      "22aaeeb7f64c408da52c713d26c5c79a",
      "36c16894ceef4b639a70639b64fa8656",
      "0c902a0f59474f019aac8454c609d8c8",
      "a50edb3650774aa6804be57ff2679912",
      "5b36fed42bac48df8f6be5c64b87352d",
      "c99499c39595481aae9ed033e830488d",
      "34e31945150b403aac7c18505bcffebe",
      "e098368dc726499eb30301fc7ec96680",
      "57fa33a2adcf46fab98d50ba4272e6d4",
      "414df4b27a4743b19f9619b5873af928",
      "d123af67709c407f8549fa68ff75c84c",
      "ac6cf558b8104eeabbadef90d31b1001",
      "4ea89251b87b4712899c81aca3d97489",
      "579e2463aed34e1291e4d5631c44fc65",
      "16e7201c006643c6a0fc82f023a4f0d4",
      "848e47d79d7b42ec9300712a6db2490d",
      "da9769cdb6fa4799b57704c747c3f369",
      "5a46f0902c1d4039bbfd65f49db949fe",
      "a2eeca25333942ff85f46cfb62c18fa7",
      "570d345b74c54ed8a2daa43ff964b565",
      "7d032d6ff2094db38d4d753fd30c18ae",
      "ad2362a52e3141edb33cf742ad776261",
      "798a84d1da02468b9bc74a5592732c7e",
      "68fab800d36f492d9f281bb107713712",
      "d2cb0da008db44d4bbb7b5bc1f7047d4",
      "075c866090fc470ca20c6ea3fc361b09",
      "34a4412d9694441c85dacda083f135f9",
      "f11aa7a98c26408da8d3eee0e701319e",
      "d93825d645f54b78ae64e8d972d7f9b7",
      "0bdd6a3143f84a7ebea757bb0743e2de",
      "9f84c72f99a4490a94d42177d700b289",
      "d255b85ac1364562869d4c75c477ad74",
      "c2b2f8d16f894ea9937bbd573a8d8828",
      "8ac4ab8095634753977617dd8c4fca35",
      "e8900ecea4e84c0e8c0438a44bfc79c4",
      "289760e405614678b4d91dc507a2f71c",
      "1a0a8a324df443fd849699a6d7acdcd1",
      "e181e878c2d44b06bb090f517164b5d8",
      "947b25cee4fc4aa7984b34f64c2390fd",
      "195261e18fd3479699aa26fe5c08a3d2",
      "15b1c50836c84da3829ece038c04a00a",
      "526e3ac437814233bd6612b70ab797a9",
      "63ffe8ae098c4875b57acdc133987800",
      "fba75df24cec4e8d99bbc7a291c7f688",
      "657826b3fb2e41f4b5018e66e08da371",
      "76645ae9cf114486b00c6b02d45dcba1",
      "8a5499081492417689119e012adc9b70",
      "6a5fa254a88641f99814ef8df771c448",
      "9bee7f28a9ac426fb1fd3ed9522053df",
      "f2edfc5abc64471f8a24096f86451da5",
      "b70b6b1334a94f7b958d91176a5d26d9",
      "973b5fe4f148467c94fcf271c6946153",
      "506402cdd6ad40738589621155fe2f95",
      "547322023b1f4562bca98248f8ef4fd7",
      "e7a4c84b68e241a6b4614f72358097e2",
      "181621e39f6048e794403c3dcf7fdd5f",
      "12e9d9bc8818420a87e8594c30df5ca4",
      "40042259079142ceb85e20b5f9fe1bc3",
      "7816dc8a9976406193cde9276813140c",
      "7fd509c26f694cb6ba827a8acd5a4a75",
      "1cb9c2abb2a04fedb554e75b6a77a8cb",
      "9c7439ff452746358ab1dc7001c6e3e6",
      "8583e81cc266408a80d392eb3c0d743d",
      "b0087a30bc1446ccad4db76a94aceec0",
      "0ae7e3defcf045828b66b8fee5fa4ba4",
      "397da3892a2449daa9c9b0f221f78b22",
      "d11db4a4cbd7438f99aebd4d4bf28331",
      "f234d3bd03d9456ab511e4fb384f281f",
      "be4c55de5ce7413ba7434a3ec122c2d1",
      "c4f3e6bac4cf48f58835f2b19ac4b04c",
      "d7c2b09699034442a02f1b57ef58c86e",
      "e5268519067a469088d96b1221735ab9",
      "11cb24e4a6d6483a9a4b2c8c5134780f",
      "956d94e903c54a21af759e1a8cbc9133",
      "69cd5de160f64784bc470f7aead702a5",
      "55e2f3c488dc4f5b8a6aee6c1236018f",
      "fd62b9288aac4961b7addb375f18c39a",
      "88cb22ddc558459fbacfcbf1a0cdf28d",
      "d2ab2997912846b09fb1c9c864c824a1",
      "ced9931973ad4acaaac4adf9fcd3a1c9",
      "e912ff1a92374c9bb75be2b6edda86aa",
      "4100532679d24d08aa0bba794efb216b",
      "fdc61059e5e04385a594a75935b5f29a",
      "a6deb547f17a46f4a83aebc6c36cfe70",
      "880f0af269bb45aaa2ab2f214cd4f531",
      "6dafcd0807894a59bee70cd426caf2b0",
      "bb89ee776eb54a98b7afa968105fdbda",
      "88cfa0f6c00b4b6b811d99da7aa49ed8",
      "865961aba07b408e84e95dac7cd4db80",
      "18c30f78374645beb272a784d91afd78",
      "7efa19a815314fe289bcebddccf94471",
      "a6336e51a5614949890833bc9235b546",
      "89f48f1eaa914936932af31dba2e82a2",
      "8106872f9df045e4ac40be0548471c2a",
      "4754407eea1e4d41beaa7115ba1b3a7c",
      "a8514d3147ad4ca4901233127989d6c1",
      "eec73c4edb1c468a842daddbf4ff2b17",
      "c7f8f99d93cc4f3eb901b5b209895279",
      "afcc650881d3473d8e763cc7502c7bfe",
      "eb11685fd5cb407fa89e9605dc81897c",
      "fa2bf55d66bc48ecb7b60f750d492f95",
      "d8a9dc5c17044944962f88953205f51c",
      "6b79af7722884c599f28308ebebe8ed2",
      "765808852eed4e1384a1aa545c5b10c5",
      "3f3967b8acf741969f820c0f2a44ed86",
      "1845480bc99741f38da188c1252b07d0",
      "43099782a5564483a3761d5d89aaf401",
      "74c79ceb845b4fc19a3b3ab3edbd02d5",
      "f4762421c53a43e38404fd91b130f970",
      "a5f2d2193c3c430a8ca8b40b7cab8cec",
      "7d1169a22d574ae0989c9de13979220a",
      "072292c905534e3bb4ef53faf65f9e07",
      "cbe1cd9a44a546fca7d0a6532e85ee9f",
      "a67b2a74872940098dbdeda7a1e40dc5",
      "d8202a60052c47a99bb8581d0d7afa7a",
      "b4fffe3b5fe64ad2a658959ab82b504a",
      "e978bbdea1e9459a805be9db26c0c613",
      "16ce41edcc8d4b3f835b9d65e43ee69e",
      "e37e08a7343345a5b7f47204ed6865fc",
      "3eea3e9f9a2b418ea4d0d8299de1a413",
      "8fd92ab5acba4a09857dc2a65db874f9",
      "d6e88cc60601454ab7a56526d622cd35",
      "2a8dfa8fb171403d9728a2c16e855a6c",
      "55c0c874d3fc4d9188343ef46ecbb9de",
      "fdb3d2010e47468893b003c91258eb83",
      "e52d33f0825e41df8cc0a09e36dd4b54",
      "b9c398bfaa6b4660b232574899410a37",
      "d56e0d214b6f4adb9a451c7c32da836e",
      "2ca169f1c5ab44e595ec459075f6db7f",
      "d6a1494f2ea14d7588930b438d7cdf04",
      "6468130af68646fdb00809ca348865bc",
      "e08879455a8248b7ab6c2b1dc0bd8ca8",
      "2bed60cfd6554206ad27ce053a8413fb",
      "7e84d9256cba431b9e10f3a89eca898d",
      "25c6be6244d64a339c74a7f6e872238e",
      "9d62a024ad3e4edda1bc837a238d0f73",
      "e1de56af663e416698f193885c66dbfb",
      "424523c1db0848deacb25392ba471aec",
      "ddd405075d9b4586a0db9e401dc6b387",
      "a50576811a82415cba9a5619e8f5a323",
      "c6e36ff8d2c14cb896b303561532ccfa",
      "d95f72eeba50484ea2716ef327a2e3f6",
      "5760c15beaca4d35872ee9bb281ccb10",
      "f9f37f276f3447139f8a1c94ea9ebf66",
      "883c78d38dfb4d0c8c10d16f960f2a93",
      "8331e5b6e75a40308e66af76c687004f",
      "68d67df3cddb42abad0c51f39f502693",
      "f16c448ced4840929ba23183f3e90c5a",
      "ebdd9706ceec4fb3904209a7f17731ca",
      "63a079b29eab4da3902d9358f8871215",
      "503d4b4533b44f01913f084728ada8a7",
      "d83eade6356341fb975f0a07b3cb438e",
      "e5940858e5aa48a1b0fd89442af92ecd",
      "2efaf79934fa465ab946cdc568ad093b",
      "a992323c66024d8bb51c97f89b151e43",
      "04022795dd4542799c234e676783acf4",
      "6dfcae2f64ff4c29925ca1b4c3b23834",
      "36de2df6f6264ce9b00f8d0de186c48f",
      "f1d2edbeedb94f76821cbbe3cc0bd1ce",
      "b30c57c3465741daa0f3f4c12947c26f",
      "bd783964266d4da28c431d89350c5d84",
      "bdc1449a1aad4d879422e3139b4a4fe9",
      "26b5a53fac9d49c9a7c9230bc9aa07a3",
      "4298ae76d3e54d43a0197846e0f4f6d1"
     ]
    },
    "executionInfo": {
     "elapsed": 298851,
     "status": "ok",
     "timestamp": 1767370611451,
     "user": {
      "displayName": "Stefan Lafon",
      "userId": "17149650627927548318"
     },
     "user_tz": 480
    },
    "id": "VffXDzuemewD",
    "outputId": "e0aeb9a1-4481-4605-d63b-665e76ee9994"
   },
   "outputs": [],
   "source": [
    "# @title 2. Load model and stage 1 adapter\n",
    "import torch\n",
    "from transformers import Qwen2VLForConditionalGeneration, AutoProcessor, BitsAndBytesConfig\n",
    "from peft import PeftModel\n",
    "import os\n",
    "\n",
    "# 1. Configuration and committed checkpoint.\n",
    "MODEL_ID = \"Qwen/Qwen2-VL-7B-Instruct\"\n",
    "# Updated to point to your finalized Stage 1 weights.\n",
    "ADAPTER_PATH = os.path.join(PROJECT_ROOT, 'checkpoints/stage1_final')\n",
    "\n",
    "# 2. Initialize processor first to ensure it is defined for later cells.\n",
    "print(f\"Loading processor for {MODEL_ID}...\")\n",
    "processor = AutoProcessor.from_pretrained(MODEL_ID, min_pixels=256*256, max_pixels=256*256)\n",
    "\n",
    "if not os.path.exists(ADAPTER_PATH):\n",
    "    print(f\"[ERROR] Checkpoint not found at {ADAPTER_PATH}.\")\n",
    "    print(\"Ensure you have run the training notebook to completion.\")\n",
    "else:\n",
    "    # 3. Load the base model in 4-bit for T4 memory safety.\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=torch.float16,\n",
    "    )\n",
    "\n",
    "    print(f\"Loading base model and applying adapter...\")\n",
    "    base_model = Qwen2VLForConditionalGeneration.from_pretrained(\n",
    "        MODEL_ID,\n",
    "        quantization_config=bnb_config,\n",
    "        device_map=\"auto\",\n",
    "        torch_dtype=torch.float16,\n",
    "        trust_remote_code=True\n",
    "    )\n",
    "\n",
    "    # 4. Apply the Stage 1 final adapter.\n",
    "    model = PeftModel.from_pretrained(base_model, ADAPTER_PATH)\n",
    "    model.eval()\n",
    "\n",
    "    print(\"[SUCCESS] Stage 1 model and processor ready for evaluation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 650
    },
    "executionInfo": {
     "elapsed": 90842,
     "status": "ok",
     "timestamp": 1767371854459,
     "user": {
      "displayName": "Stefan Lafon",
      "userId": "17149650627927548318"
     },
     "user_tz": 480
    },
    "id": "x_dkDGv2p1wp",
    "outputId": "8bdd30dc-9473-44a7-bac9-ee86ab80858e"
   },
   "outputs": [],
   "source": [
    "# @title 3. Inference: The full diagnostic and 5-column view\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import textwrap\n",
    "import gc\n",
    "import torch\n",
    "import os\n",
    "\n",
    "# 1. Access the generator logic from your project lib.\n",
    "from generators.primitives import generate_primitive\n",
    "\n",
    "# This prompt must match the one used in the training collator logic exactly.\n",
    "SYSTEM_PROMPT = \"You are an EarthShader SDF compiler. Translate the visual primitive into a valid GLSL mainImage function using the common.glsl library.\"\n",
    "\n",
    "def parse_response(text):\n",
    "    \"\"\"Splits model output into analysis and code sections.\"\"\"\n",
    "    code_start_markers = [\"```glsl\", \"void mainImage\", \"//\"]\n",
    "    idx = -1\n",
    "    for marker in code_start_markers:\n",
    "        idx = text.find(marker)\n",
    "        if idx != -1: break\n",
    "\n",
    "    if idx != -1:\n",
    "        analysis = text[:idx].strip()\n",
    "        code_raw = text[idx:].strip()\n",
    "        if code_raw.startswith(\"```glsl\"): code_raw = code_raw[7:]\n",
    "        if code_raw.endswith(\"```\"): code_raw = code_raw[:-3]\n",
    "        return analysis, code_raw.strip()\n",
    "    return text, \"\"\n",
    "\n",
    "# 2. Diagnostic loop.\n",
    "num_samples = 3\n",
    "plt.figure(figsize=(30, 12))\n",
    "\n",
    "for i in range(num_samples):\n",
    "    print(f\"Testing sample {i+1}...\")\n",
    "\n",
    "    # A. Generate input (Ground Truth).\n",
    "    # Using random seeds outside the training range (0-2000) for fair testing.\n",
    "    gt_code, gt_analysis = generate_primitive(random.randint(5000, 10000))\n",
    "    renderer.render(gt_code, \"temp_gt.png\")\n",
    "    gt_image = Image.open(\"temp_gt.png\").convert(\"RGB\")\n",
    "\n",
    "    # B. Prompt construction matching the training collator logic.\n",
    "    conversation = [\n",
    "        {\"role\": \"system\", \"content\": [{\"type\": \"text\", \"text\": SYSTEM_PROMPT}]},\n",
    "        {\"role\": \"user\", \"content\": [\n",
    "            {\"type\": \"image\"},\n",
    "            {\"type\": \"text\", \"text\": \"Reverse engineer the GLSL shader code for this texture. Include analysis.\"}\n",
    "        ]}\n",
    "    ]\n",
    "    prompt = processor.apply_chat_template(conversation, add_generation_prompt=True, tokenize=False)\n",
    "    inputs = processor(text=[prompt], images=[gt_image], padding=True, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    # C. Generate with low temperature for stable reasoning.\n",
    "    with torch.no_grad():\n",
    "        output_ids = model.generate(**inputs, max_new_tokens=1024, temperature=0.2, do_sample=True)\n",
    "\n",
    "    # D. Cleanup and decode.\n",
    "    generated_ids = output_ids[:, inputs.input_ids.shape[1]:]\n",
    "    output_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "    pred_analysis, pred_code = parse_response(output_text)\n",
    "\n",
    "    # E. Render model output.\n",
    "    temp_pred_path = f\"temp_pred_{i}.png\"\n",
    "    pred_success = renderer.render(pred_code, temp_pred_path)\n",
    "\n",
    "    if pred_success and os.path.exists(temp_pred_path):\n",
    "        pred_image = Image.open(temp_pred_path)\n",
    "    else:\n",
    "        # Create a dark red fallback to indicate a compilation/rendering failure.\n",
    "        pred_image = Image.new(\"RGB\", (256, 256), (100, 0, 0))\n",
    "\n",
    "    # --- VISUALIZATION (5 Columns) ---\n",
    "    plt.subplot(num_samples, 5, i*5 + 1); plt.imshow(gt_image); plt.title(\"Input (GT)\"); plt.axis('off')\n",
    "    plt.subplot(num_samples, 5, i*5 + 2); plt.imshow(pred_image); plt.title(\"Model Result\"); plt.axis('off')\n",
    "\n",
    "    ax3 = plt.subplot(num_samples, 5, i*5 + 3)\n",
    "    plt.text(0, 1, textwrap.fill(gt_analysis, width=35), fontsize=9, va='top'); plt.title(\"GT Logic\"); plt.axis('off')\n",
    "\n",
    "    ax4 = plt.subplot(num_samples, 5, i*5 + 4)\n",
    "    plt.text(0, 1, textwrap.fill(pred_analysis, width=35), fontsize=9, va='top', color='blue'); plt.title(\"Model Reasoning\"); plt.axis('off')\n",
    "\n",
    "    ax5 = plt.subplot(num_samples, 5, i*5 + 5)\n",
    "    plt.text(0, 1, pred_code[:600], family='monospace', fontsize=8, va='top'); plt.title(\"Generated Code\"); plt.axis('off')\n",
    "\n",
    "    # F. Memory cleanup.\n",
    "    del inputs, output_ids, generated_ids\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 34888,
     "status": "ok",
     "timestamp": 1767370766340,
     "user": {
      "displayName": "Stefan Lafon",
      "userId": "17149650627927548318"
     },
     "user_tz": 480
    },
    "id": "CXz-viSlB5Qw",
    "outputId": "efa0db2b-ff48-49d5-a257-a5703650a098"
   },
   "outputs": [],
   "source": [
    "# @title 4. Raw output dump and diagnostic\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "# The system prompt anchors the model to its \"compiler\" persona.\n",
    "SYSTEM_PROMPT = \"You are an EarthShader SDF compiler. Translate the visual primitive into a valid GLSL mainImage function using the common.glsl library.\"\n",
    "\n",
    "# 1. Reset metrics and run a single, deep test.\n",
    "num_samples = 1\n",
    "\n",
    "for i in range(num_samples):\n",
    "    # A. Generate Ground Truth Input.\n",
    "    gt_code, gt_analysis = generate_primitive(random.randint(0, 100000))\n",
    "    renderer.render(gt_code, \"temp_gt.png\")\n",
    "    gt_image = Image.open(\"temp_gt.png\").convert(\"RGB\")\n",
    "\n",
    "    # B. Generate Prediction with the system role included.\n",
    "    conversation = [\n",
    "        {\"role\": \"system\", \"content\": [{\"type\": \"text\", \"text\": SYSTEM_PROMPT}]},\n",
    "        {\"role\": \"user\", \"content\": [\n",
    "            {\"type\": \"image\"},\n",
    "            {\"type\": \"text\", \"text\": \"Reverse engineer the GLSL shader code for this texture. Include analysis.\"}\n",
    "        ]}\n",
    "    ]\n",
    "    prompt = processor.apply_chat_template(conversation, add_generation_prompt=True, tokenize=False)\n",
    "    inputs = processor(text=[prompt], images=[gt_image], padding=True, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    # Low temperature helps maintain structural consistency.\n",
    "    with torch.no_grad():\n",
    "        output_ids = model.generate(**inputs, max_new_tokens=1024, temperature=0.1, do_sample=True)\n",
    "\n",
    "    generated_ids = output_ids[:, inputs.input_ids.shape[1]:]\n",
    "    output_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "\n",
    "    # --- RAW OUTPUT DUMP ---\n",
    "    print(f\"\\n{'='*60}\\nSAMPLE {i+1} RAW OUTPUT\\n{'='*60}\")\n",
    "    print(output_text)\n",
    "    print(f\"{'='*60}\\n\")\n",
    "\n",
    "    # C. Cleanup.\n",
    "    del inputs, output_ids\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNwOM/zp8PmC7Zz6GacovOD",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
