{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNK+l8cfjoQK1FBW/aNiPG+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["**Stage 1 - Validation**"],"metadata":{"id":"htfgqge_kAIY"}},{"cell_type":"code","source":["# @title 1. Install Dependencies\n","import os\n","import sys\n","\n","# 1.1 Force Upgrade Libraries\n","print(\"Installing libraries...\")\n","!pip install -q -U bitsandbytes\n","!pip install -q -U git+https://github.com/huggingface/transformers peft accelerate\n","!pip install -q moderngl\n","!apt-get install -y libgl1-mesa-glx > /dev/null\n","\n","# 1.2 Restart Check\n","try:\n","    import bitsandbytes\n","    from transformers.utils import is_bitsandbytes_available\n","    if not is_bitsandbytes_available():\n","        print(\"\\n\" + \"=\"*60)\n","        print(\"  PLEASE RESTART RUNTIME (Runtime > Restart Session)\")\n","        print(\"Then run this cell again.\")\n","        print(\"=\"*60 + \"\\n\")\n","    else:\n","        print(\"  Environment Ready.\")\n","except ImportError:\n","    pass"],"metadata":{"cellView":"form","id":"lgGsUkWyiUjO","collapsed":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title 2. Load Model & Adapter\n","import torch\n","from transformers import Qwen2VLForConditionalGeneration, Qwen2VLProcessor, BitsAndBytesConfig\n","from peft import PeftModel\n","import os\n","import sys\n","import importlib.util\n","\n","# 2.1 Configuration\n","PROJECT_ROOT = '/content/drive/MyDrive/projects/EarthShader'\n","ADAPTER_PATH = os.path.join(PROJECT_ROOT, 'checkpoints/stage1_final')\n","LIB_DIR = os.path.join(PROJECT_ROOT, 'lib')\n","\n","# 2.2 Mount Drive\n","from google.colab import drive\n","if not os.path.exists('/content/drive'):\n","    drive.mount('/content/drive')\n","\n","# 2.3 Setup Renderer\n","sys.path.append(PROJECT_ROOT)\n","if LIB_DIR not in sys.path:\n","    sys.path.insert(0, LIB_DIR)\n","\n","try:\n","    from gl_renderer import ShaderRenderer\n","    # Initialize renderer once to hold the context\n","    renderer = ShaderRenderer(width=256, height=256)\n","    print(\"[SUCCESS] Renderer ready.\")\n","except ImportError:\n","    spec = importlib.util.spec_from_file_location(\"gl_renderer\", os.path.join(LIB_DIR, \"gl_renderer.py\"))\n","    mod = importlib.util.module_from_spec(spec)\n","    spec.loader.exec_module(mod)\n","    renderer = mod.ShaderRenderer(width=256, height=256)\n","    print(\"[SUCCESS] Renderer ready (Direct Load).\")\n","\n","# 2.4 Load Model\n","print(f\"⏳ Loading Adapter from: {ADAPTER_PATH}...\")\n","\n","bnb_config = BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_quant_type=\"nf4\",\n","    bnb_4bit_compute_dtype=torch.float16,\n",")\n","\n","# Load Base\n","base_model = Qwen2VLForConditionalGeneration.from_pretrained(\n","    \"Qwen/Qwen2-VL-7B-Instruct\",\n","    quantization_config=bnb_config,\n","    device_map=\"auto\",\n","    torch_dtype=torch.float16,\n",")\n","\n","# Load Adapter\n","model = PeftModel.from_pretrained(base_model, ADAPTER_PATH)\n","processor = Qwen2VLProcessor.from_pretrained(\"Qwen/Qwen2-VL-7B-Instruct\")\n","\n","print(\"[SUCCESS] Model Loaded Successfully!\")"],"metadata":{"cellView":"form","id":"VffXDzuemewD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title 3. Generate & Validate Samples (Using Library)\n","import random\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","import torch\n","import os\n","import sys\n","import re\n","import importlib.util\n","\n","# 1. Import Generator from Library\n","# We assume LIB_DIR is already in sys.path from Cell 2, but let's be safe\n","PROJECT_ROOT = '/content/drive/MyDrive/projects/EarthShader'\n","LIB_DIR = os.path.join(PROJECT_ROOT, 'lib')\n","if LIB_DIR not in sys.path:\n","    sys.path.insert(0, LIB_DIR)\n","\n","try:\n","    from generators.primitives import generate_primitive\n","    print(\"✅ Generator library loaded.\")\n","except ImportError as e:\n","    print(f\"Library import failed: {e}. Trying direct load...\")\n","    # Direct load fallback if Colab package resolution is flaky\n","    spec_b = importlib.util.spec_from_file_location(\"base\", os.path.join(LIB_DIR, \"generators/base.py\"))\n","    mod_b = importlib.util.module_from_spec(spec_b)\n","    spec_b.loader.exec_module(mod_b)\n","\n","    spec_p = importlib.util.spec_from_file_location(\"primitives\", os.path.join(LIB_DIR, \"generators/primitives.py\"))\n","    mod_p = importlib.util.module_from_spec(spec_p)\n","    mod_p.base = mod_b # Inject dependency\n","    spec_p.loader.exec_module(mod_p)\n","    generate_primitive = mod_p.generate_primitive\n","\n","# 2. Helpers\n","def extract_code(text):\n","    if \"// GLSL CODE\" in text:\n","        return text.split(\"// GLSL CODE\")[1].strip()\n","    if \"```glsl\" in text:\n","        return text.split(\"```glsl\")[1].split(\"```\")[0].strip()\n","    return text\n","\n","def parse_shape_name(analysis_text):\n","    # Extract \"Shape: Circle\" from analysis block\n","    match = re.search(r\"// Shape: (\\w+)\", analysis_text)\n","    return match.group(1) if match else \"Unknown\"\n","\n","# 3. Inference Loop\n","print(\"Running Inference on 3 Random Samples...\")\n","plt.figure(figsize=(15, 10))\n","\n","for i in range(3):\n","    # A. Generate Ground Truth using Library\n","    gt_code, gt_analysis = generate_primitive(i)\n","    shape_name = parse_shape_name(gt_analysis)\n","\n","    renderer.render(gt_code, \"temp_gt.png\")\n","    gt_image = Image.open(\"temp_gt.png\").convert(\"RGB\")\n","\n","    # B. Prompt\n","    conversation = [\n","        {\n","            \"role\": \"user\",\n","            \"content\": [\n","                {\"type\": \"image\", \"image\": \"temp_gt.png\"},\n","                {\"type\": \"text\", \"text\": \"Reverse engineer the GLSL shader code for this texture. Include analysis.\"}\n","            ]\n","        }\n","    ]\n","\n","    text_prompt = processor.apply_chat_template(conversation, add_generation_prompt=True)\n","    inputs = processor(\n","        text=[text_prompt],\n","        images=[gt_image],\n","        padding=True,\n","        return_tensors=\"pt\"\n","    ).to(model.device)\n","\n","    # C. Generate\n","    with torch.no_grad():\n","        output_ids = model.generate(**inputs, max_new_tokens=512)\n","\n","    generated_ids = [output_ids[len(inputs.input_ids[0]):] for output_ids in output_ids]\n","    output_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n","\n","    # D. Render Result\n","    pred_code = extract_code(output_text)\n","    renderer.render(pred_code, f\"temp_pred_{i}.png\")\n","\n","    if os.path.exists(f\"temp_pred_{i}.png\"):\n","        pred_image = Image.open(f\"temp_pred_{i}.png\")\n","    else:\n","        pred_image = Image.new(\"RGB\", (256, 256), (255, 0, 0))\n","\n","    # E. Display\n","    # GT\n","    plt.subplot(3, 3, i*3 + 1)\n","    plt.imshow(gt_image)\n","    plt.title(f\"Target: {shape_name}\", fontsize=10)\n","    plt.axis('off')\n","\n","    # Pred\n","    plt.subplot(3, 3, i*3 + 2)\n","    plt.imshow(pred_image)\n","    plt.title(\"Model Prediction\", fontsize=10)\n","    plt.axis('off')\n","\n","    # Code\n","    ax = plt.subplot(3, 3, i*3 + 3)\n","    clean_code = pred_code.replace(\"void mainImage\", \"// Generated\\nvoid mainImage\")\n","    plt.text(0, 1, clean_code[:600], family='monospace', fontsize=8, verticalalignment='top')\n","    plt.axis('off')\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"x_dkDGv2p1wp","cellView":"form"},"execution_count":null,"outputs":[]}]}